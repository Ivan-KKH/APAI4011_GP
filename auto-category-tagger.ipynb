{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ivan-KKH/APAI4011_GP/blob/master/predicting_category.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ObWn2EbyFv_a"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import io\n",
        "import re\n",
        "from string import punctuation\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from keras.layers import Bidirectional\n",
        "import warnings\n",
        "import random\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "osq4rvsIFzCH",
        "outputId": "48704b7b-c0d4-4785-bc57-2852703ee074"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5277d5ee-1413-4191-ae7b-39b05fd3ba21\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5277d5ee-1413-4191-ae7b-39b05fd3ba21\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving amazon.csv to amazon.csv\n"
          ]
        }
      ],
      "source": [
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "L9uv8KXfGLx7"
      },
      "outputs": [],
      "source": [
        "#read csv file\n",
        "df = pd.read_csv(io.BytesIO(uploaded['amazon.csv']))\n",
        "#dfReview for review title and review content\n",
        "dfText = df[['product_name','about_product','category']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hP6eO3KgHK77"
      },
      "outputs": [],
      "source": [
        "for column in range(2):\n",
        "  dfText.iloc[:,column] = dfText.iloc[:,column].apply(lambda x: x.lower())\n",
        "  dfText.iloc[:,column] = dfText.iloc[:,column].apply((lambda x: re.sub(r\"http\\S+\",\" \",x)))\n",
        "  dfText.iloc[:,column] = dfText.iloc[:,column].apply((lambda x: re.sub('[^a-zA-z0-9\\s]',\" \",x)))\n",
        "dfText['category'] = dfText['category'].apply(lambda x: x.split('|',1)[0])\n",
        "\n",
        "#combine product_name and about_product\n",
        "dfText['combined'] = dfText['product_name'] + ' ' + dfText['about_product']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmmCvkPVJ53x",
        "outputId": "d6b3fc24-3d93-468f-f229-47413ac81db3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "category list: ['Computers&Accessories', 'Electronics', 'MusicalInstruments', 'OfficeProducts', 'Home&Kitchen', 'HomeImprovement', 'Toys&Games', 'Car&Motorbike', 'Health&PersonalCare']\n",
            "shape of text: (1465, 424)\n",
            "shape of category: (1465, 9)\n"
          ]
        }
      ],
      "source": [
        "#tokenize, build vocab, and add paddings on product_name\n",
        "tokenizer = Tokenizer(num_words=2000,split=' ')\n",
        "tokenizer.fit_on_texts(dfText['combined'].values)\n",
        "text = tokenizer.texts_to_sequences(dfText['combined'].values)\n",
        "text = pad_sequences(text)\n",
        "\n",
        "#category\n",
        "category_list = []\n",
        "for categ in dfText['category']:\n",
        "  if categ not in category_list:\n",
        "    category_list.append(categ)\n",
        "print(f'category list: {category_list}')\n",
        "category = pd.get_dummies(dfText['category'], columns=category_list).values\n",
        "category_list = ['Car & Motorbike', 'Computers & Accessories', 'Electronics', 'Health & Personal Care', 'Home & Kitchen', 'Home Improvement', 'Musical Instruments', 'Office Products', 'Toys & Games']\n",
        "\n",
        "print(f'shape of text: {text.shape}')\n",
        "print(f'shape of category: {category.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fn8_2SbpKZV3"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, Embedding, LSTM, Dense, concatenate, Flatten, Reshape, SpatialDropout1D\n",
        "from keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3SZLplpLmvS",
        "outputId": "cc04e1fc-2988-4f6c-d067-8fd0bb0942dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1172, 424) (1172, 9)\n",
            "(293, 424) (293, 9)\n",
            "Epoch 1/10\n",
            "37/37 [==============================] - 104s 3s/step - loss: 1.4114 - accuracy: 0.3481 - val_loss: 1.2616 - val_accuracy: 0.3447\n",
            "Epoch 2/10\n",
            "37/37 [==============================] - 100s 3s/step - loss: 1.2012 - accuracy: 0.3848 - val_loss: 1.1864 - val_accuracy: 0.3618\n",
            "Epoch 3/10\n",
            "37/37 [==============================] - 98s 3s/step - loss: 1.0368 - accuracy: 0.6015 - val_loss: 1.2471 - val_accuracy: 0.3754\n",
            "Epoch 4/10\n",
            "37/37 [==============================] - 101s 3s/step - loss: 0.6356 - accuracy: 0.7824 - val_loss: 0.6314 - val_accuracy: 0.8123\n",
            "Epoch 5/10\n",
            "37/37 [==============================] - 102s 3s/step - loss: 0.3472 - accuracy: 0.8771 - val_loss: 0.3675 - val_accuracy: 0.8840\n",
            "Epoch 6/10\n",
            "37/37 [==============================] - 102s 3s/step - loss: 0.2109 - accuracy: 0.9317 - val_loss: 0.4201 - val_accuracy: 0.8840\n",
            "Epoch 7/10\n",
            "37/37 [==============================] - 102s 3s/step - loss: 0.1400 - accuracy: 0.9582 - val_loss: 0.3366 - val_accuracy: 0.8976\n",
            "Epoch 8/10\n",
            "37/37 [==============================] - 102s 3s/step - loss: 0.1052 - accuracy: 0.9684 - val_loss: 0.3311 - val_accuracy: 0.9181\n",
            "Epoch 9/10\n",
            "37/37 [==============================] - 98s 3s/step - loss: 0.0803 - accuracy: 0.9778 - val_loss: 0.3609 - val_accuracy: 0.9010\n",
            "Epoch 10/10\n",
            "37/37 [==============================] - 97s 3s/step - loss: 0.0545 - accuracy: 0.9872 - val_loss: 0.3751 - val_accuracy: 0.8874\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f79841f91f0>"
            ]
          },
          "execution_count": 162,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#split data\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(text, category, test_size=0.2, random_state=42)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)\n",
        "\n",
        "#apply Bidirectional LSTM\n",
        "model = Sequential()\n",
        "model.add(Embedding(2000, 128, input_length = 424))\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(Bidirectional(LSTM(196, dropout=0.2, recurrent_dropout=0.2)))\n",
        "model.add(Dense(9,activation='softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "\n",
        "#Train the model for 5 epoches with embedding matrix you obtained earlier.\n",
        "#print training loss and training accuracy for each epoch\n",
        "model.fit(X_train, Y_train, epochs=10, batch_size=32, validation_data=(X_test,Y_test))  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugrV04vuY4DJ",
        "outputId": "fbf09e2f-648c-42b3-aad2-06688193702a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "424\n",
            "1/1 [==============================] - 0s 176ms/step\n",
            "Product name: Fire-Boltt Ninja Call Pro Plus 1.83\" Smart Watch with Bluetooth Calling, AI Voice Assistance, 100 Sports Modes IP67 Rating, 240*280 Pixel High Resolution\n",
            "Product description: Fire-Boltt is India' No 1 Wearable Watch Brand Q122 by IDC Worldwide quarterly wearable device tracker Q122.【Bluetooth Calling Watch】- Fire-Boltt Ninja Call Pro Plus Smart Watch enables you to make and receive calls directly from your watch via the built-in speaker and microphone. This smartwatch features a dial pad, option to access recent calls & sync your phone’s contacts.|【1.83\" HD Display Smartwatch】- The 46.48mm (1.83-inch) HD display makes the display clear and true-to-life, with vivid colours ensuring smooth readability and keeping the watch as exquisite to look at as when you first lay your eyes on it.|【AI Voice Assistant】- With built-in Voice assistant, you can simply speak to the smartwatch & get things done on your command|【100 Sport Modes】- Track every trek you take or every football, cricket kabaddi match you play. With over 100 sports modes Fire-Boltt Ninja Call Pro Plus has you covered.|【Fire-Boltt Health Suite】- With advanced technology and HRS chipset the smartwatch can give out near to accurate SpO2, Heart Rate readings. This mini health device tracks your sleep to ensure glowing and fresh look each day\n",
            "Predicted Category: Electronics\n",
            "Actual Category: Electronics\n"
          ]
        }
      ],
      "source": [
        "#a simple predictor function\n",
        "def predict(product_name, about_product):\n",
        "    # Convert to lowercase\n",
        "    name = product_name.lower()\n",
        "    desc = about_product.lower()\n",
        "\n",
        "    #remove punctuation\n",
        "    name = re.sub(r\"http\\S+\",\" \",name)\n",
        "    desc = re.sub(r\"http\\S+\",\" \",desc)\n",
        "\n",
        "    #text\n",
        "    text = name + ' ' + desc\n",
        "\n",
        "    #tokenize, build vocab, and add paddings on product_name\n",
        "    text = tokenizer.texts_to_sequences(text)\n",
        "    token_list = []\n",
        "    for element in text:\n",
        "        if element:\n",
        "            token_list.append(element[0])\n",
        "    token_list = token_list[:423]\n",
        "    token_len = len(token_list)\n",
        "\n",
        "    #pad sequence\n",
        "    zero_list = np.zeros(424 - token_len)\n",
        "    padded_list = [*zero_list, *token_list]\n",
        "    padded_list = [padded_list]\n",
        "\n",
        "    #predict category\n",
        "    pred = model.predict(padded_list)\n",
        "    max_idx = np.argmax(pred)\n",
        "    predicted_category = category_list[max_idx]\n",
        "\n",
        "    return predicted_category\n",
        "\n",
        "#choose a random product\n",
        "rand_idx = random.randint(0,1465)\n",
        "product_name = df['product_name'][rand_idx]\n",
        "about_product = df['about_product'][rand_idx]\n",
        "\n",
        "#predict its category\n",
        "pred_categ = predict(product_name, about_product)\n",
        "actual_category = np.argmax(category[rand_idx])\n",
        "print(f\"Product name: {product_name}\")\n",
        "print(f\"Product description: {about_product}\")\n",
        "print(f'Predicted Category: {pred_categ}')\n",
        "print(f'Actual Category: {category_list[actual_category]}')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyORxWzOC4h6mBxc8EAsRnBC",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
